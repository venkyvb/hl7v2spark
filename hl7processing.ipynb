{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import com.databricks.labs.smolder.functions.parse_hl7_message\n",
        "\n",
        "val hl7Path = \"abfss://<container>@<storageaccount>.dfs.core.windows.net/hl7messages/messages.hl7\"\n",
        "val bronzePath =  \"abfss://<container>@<storageaccount>.dfs.core.windows.net/bronze\"\n",
        "\n",
        "// Load the file that has the HL7 messages from ADLS folder\n",
        "val hl7Raw = (spark.read.option(\"lineSep\", \"\\n\\n\").text(hl7Path))\n",
        "\n",
        "(hl7Raw.write.format(\"delta\").mode(\"overwrite\").save(bronzePath))\n",
        "\n",
        "val hl7Bronze = (spark.read\n",
        ".format(\"delta\")\n",
        ".load(bronzePath)\n",
        ".select(parse_hl7_message($\"value\").as(\"message\"))\n",
        ".select($\"message.message\".as(\"message\"), $\"message.segments\".as(\"segments\"))\n",
        ")\n",
        "\n",
        "// Structure the raw payload for SQL access via pyspark and move the data to a temp view\n",
        "hl7Bronze.createOrReplaceTempView(\"hl7Bronze_temp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# copy the data from the temp view to Bronze for further processing\n",
        "hl7Bronze = spark.sql(\"\"\" \n",
        "SELECT message, \n",
        "FILTER(segments, segment -> segment.id == \"PID\") as PID,\n",
        "FILTER(segments, segment -> segment.id == \"PV1\") as PV1\n",
        "FROM hl7Bronze_temp\n",
        "\"\"\"\n",
        ")\n",
        "display(hl7Bronze)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "from pyspark.sql.functions import explode, col, split, when, concat_ws, to_date\n",
        "from delta.tables import *\n",
        "\n",
        "# Process the raw data to create a structured table\n",
        "hl7BronzeProcessed = (hl7Bronze\n",
        ".withColumn(\"message_type\", split(col(\"message\"), \"\\|\").getItem(8))\n",
        ".withColumn(\"exploded_PID\", explode(\"PID\"))\n",
        ".withColumn(\"exploded_PV1\", explode(\"PV1\"))\n",
        ".select(col(\"message\"), col(\"message_type\"), col(\"exploded_PID.fields\").alias(\"PID\"), col(\"exploded_PV1.fields\").alias(\"PV1\"))\n",
        ".withColumn(\"patient_id\", split(col(\"PID\")[2], \"\\^\").getItem(0))\n",
        ".withColumn(\"first_name\", split(col(\"PID\")[4], \"\\^\").getItem(1))\n",
        ".withColumn(\"last_name\", split(col(\"PID\")[4], \"\\^\").getItem(0))\n",
        ".withColumn(\"name\", concat_ws(' ', col(\"first_name\"), col(\"last_name\")))\n",
        ".withColumn(\"gender\", col(\"PID\")[7])\n",
        ".withColumn(\"sending_facility\", split(col(\"message\"), \"\\|\").getItem(3))\n",
        ".withColumn(\"date_of_birth\", col(\"PID\")[6])\n",
        ".withColumn(\"date_of_birth\", when(col(\"date_of_birth\")==\"\", \"19000101\").otherwise(col(\"date_of_birth\")))\n",
        ".withColumn(\"date_of_birth\", to_date(col(\"date_of_birth\"), \"yyyyMMddHHmmss\"))\n",
        ".withColumn(\"patient_address\", col(\"PID\")[10])\n",
        ".withColumn(\"patient_city\", split(col(\"patient_address\"), \"\\^\").getItem(2))\n",
        ".withColumn(\"patient_country\", split(col(\"patient_address\"), \"\\^\").getItem(5))\n",
        ".withColumn(\"ethnicity\", split(col(\"PID\")[21], \"\\^\").getItem(1))\n",
        ".na.drop(subset=[\"message\",\"patient_id\"])\n",
        ".na.fill({\"name\": \"\", \"gender\": \"\", \"sending_facility\": \"\", \"patient_city\": \"\", \"patient_country\": \"\", \"ethnicity\": \"\"})\n",
        ".filter(col(\"message_type\") == \"ADT^A01\") # filter the rest of the messages and keep only ADT^A01 message\n",
        ".drop(\"PID\", \"PV1\", \"first_name\", \"last_name\", \"patient_address\")\n",
        ")\n",
        "\n",
        "display(hl7BronzeProcessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# write the processed data into Silver lake\n",
        "silverPath =  \"abfss://<container>@<storageaccount>.dfs.core.windows.net/silver\"\n",
        "\n",
        "(hl7BronzeProcessed.write\n",
        ".format(\"delta\")\n",
        ".mode(\"overwrite\")\n",
        ".save(silverPath)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# read the data from Silver to create an aggregated view\n",
        "hl7Silver = (spark.read.format(\"delta\").load(silverPath))\n",
        "hl7SilverAgg = (hl7Silver.groupBy(\"patient_city\", \"gender\").count())\n",
        "\n",
        "hl7GoldAgg = (hl7Silver\n",
        ".select(\"gender\", \"patient_city\", \"date_of_birth\")\n",
        ".join(hl7SilverAgg, [\"gender\", \"patient_city\"])\n",
        ")\n",
        "\n",
        "display(hl7GoldAgg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "python"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%pyspark\n",
        "\n",
        "# Persist the aggregated view into Gold\n",
        "goldPath =  \"abfss://<container>@<storageaccount>.dfs.core.windows.net/gold\"\n",
        "\n",
        "(hl7GoldAgg.write.format(\"delta\").mode(\"overwrite\").save(goldPath))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {
          "language": "sparksql"
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "%%sql\n",
        "\n",
        "-- sample SQL query to run on the persisted aggregated view\n",
        "\n",
        "SELECT patient_city, gender, COUNT(count) AS `Number of Patients`\n",
        "    FROM delta.`abfss://<container>@<storageaccount>.dfs.core.windows.net/gold`\n",
        "    GROUP BY patient_city, gender"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "scala"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
